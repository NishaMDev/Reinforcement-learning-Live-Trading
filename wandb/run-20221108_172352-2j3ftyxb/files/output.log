
Using cpu device
/Users/nishadevadiga/miniforge3/envs/venv/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: [33mWARN: Box bound precision lowered by casting to float16
  logger.warn(
/Users/nishadevadiga/miniforge3/envs/venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=1000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 1000      |
| train/             |           |
|    actor_loss      | -1.67e+03 |
|    critic_loss     | 3.79e+04  |
|    ent_coef        | 1.27      |
|    ent_coef_loss   | -1.74     |
|    learning_rate   | 0.0003    |
|    n_updates       | 899       |
----------------------------------
New best mean reward!
/Users/nishadevadiga/miniforge3/envs/venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=2000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 2000      |
| train/             |           |
|    actor_loss      | -4.26e+03 |
|    critic_loss     | 9.58e+04  |
|    ent_coef        | 1.77      |
|    ent_coef_loss   | -4.6      |
|    learning_rate   | 0.0003    |
|    n_updates       | 1899      |
----------------------------------
Eval num_timesteps=3000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 3000      |
| train/             |           |
|    actor_loss      | -7.07e+03 |
|    critic_loss     | 1.28e+05  |
|    ent_coef        | 2.44      |
|    ent_coef_loss   | -7.76     |
|    learning_rate   | 0.0003    |
|    n_updates       | 2899      |
----------------------------------
Eval num_timesteps=4000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 4000      |
| train/             |           |
|    actor_loss      | -9.92e+03 |
|    critic_loss     | 1.61e+05  |
|    ent_coef        | 3.34      |
|    ent_coef_loss   | -10.4     |
|    learning_rate   | 0.0003    |
|    n_updates       | 3899      |
----------------------------------
Eval num_timesteps=5000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 5000      |
| train/             |           |
|    actor_loss      | -1.26e+04 |
|    critic_loss     | 1.74e+05  |
|    ent_coef        | 4.54      |
|    ent_coef_loss   | -13       |
|    learning_rate   | 0.0003    |
|    n_updates       | 4899      |
----------------------------------
Eval num_timesteps=6000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 6000      |
| train/             |           |
|    actor_loss      | -1.52e+04 |
|    critic_loss     | 1.49e+05  |
|    ent_coef        | 6.13      |
|    ent_coef_loss   | -15.8     |
|    learning_rate   | 0.0003    |
|    n_updates       | 5899      |
----------------------------------
Eval num_timesteps=7000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 7000      |
| train/             |           |
|    actor_loss      | -1.76e+04 |
|    critic_loss     | 1.66e+05  |
|    ent_coef        | 8.24      |
|    ent_coef_loss   | -17.8     |
|    learning_rate   | 0.0003    |
|    n_updates       | 6899      |
----------------------------------
Eval num_timesteps=8000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 8000      |
| train/             |           |
|    actor_loss      | -1.97e+04 |
|    critic_loss     | 1.7e+05   |
|    ent_coef        | 11        |
|    ent_coef_loss   | -19.3     |
|    learning_rate   | 0.0003    |
|    n_updates       | 7899      |
----------------------------------
/Users/nishadevadiga/Downloads/Stock-Trading-Environment-master/render/StockTradingGraph.py:180: UserWarning: FixedFormatter should only be used together with FixedLocator
  self.price_ax.set_xticklabels(self.df['Date'].values[step_range], rotation=45,
Eval num_timesteps=9000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 5.35e+03  |
|    mean_reward     | 2.15e+07  |
| time/              |           |
|    total_timesteps | 9000      |
| train/             |           |
|    actor_loss      | -2.16e+04 |
|    critic_loss     | 1.69e+05  |
|    ent_coef        | 14.8      |
|    ent_coef_loss   | -21.1     |
|    learning_rate   | 0.0003    |
|    n_updates       | 8899      |
----------------------------------
