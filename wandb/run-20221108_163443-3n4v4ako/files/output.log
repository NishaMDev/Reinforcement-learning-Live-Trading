
Using cpu device
/Users/nishadevadiga/miniforge3/envs/venv/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: [33mWARN: Box bound precision lowered by casting to float16
  logger.warn(
/Users/nishadevadiga/miniforge3/envs/venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=1000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 1000     |
---------------------------------
New best mean reward!
/Users/nishadevadiga/miniforge3/envs/venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=2000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 2000     |
---------------------------------
Eval num_timesteps=3000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 3000     |
---------------------------------
Eval num_timesteps=4000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 4000     |
---------------------------------
Eval num_timesteps=5000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 5000     |
---------------------------------
Eval num_timesteps=6000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 6000     |
---------------------------------
Eval num_timesteps=7000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 7000     |
---------------------------------
Eval num_timesteps=8000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 8000     |
---------------------------------
Eval num_timesteps=9000, episode_reward=21503002.50 +/- 0.00
Episode length: 5354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5.35e+03 |
|    mean_reward     | 2.15e+07 |
| time/              |          |
|    total_timesteps | 9000     |
---------------------------------
Stopping training because there was no new best model in the last 4 evaluations